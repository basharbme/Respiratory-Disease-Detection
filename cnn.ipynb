{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathangupta/anaconda3/envs/e498/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/Users/nathangupta/anaconda3/envs/e498/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Split Indices\n",
    "data_size = len(df)\n",
    "test_per = 0.10\n",
    "val_per = 0.10\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.1, random_state=1)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "data_ind = np.arange(data_size)\n",
    "random.shuffle(data_ind)\n",
    "train_ind, val_ind, test_ind = np.split(data_ind, [int(1 - val_per*data_size-test_per*data_size), int(1-test_per*data_size)])\n",
    "print(len(train_ind))\n",
    "print(len(test_ind))\n",
    "print(len(val_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "x_train\n",
    "x_val\n",
    "x_test\n",
    "\n",
    "y_train\n",
    "y_val\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "\n",
    "# reshape for the network\n",
    "x_train = x_train.reshape(len(x_train), 28, 28, 1) / 255\n",
    "x_val = x_val.reshape(len(x_val), 28, 28, 1) / 255\n",
    "x_test = x_test.reshape(len(x_test), 28, 28, 1) / 255\n",
    "\n",
    "# create a linear stack of layers\n",
    "# see: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "model = models.Sequential()\n",
    "# the first layer is a convolutional layer:\n",
    "#   - 32 filters (or kernels)\n",
    "#   - kernel width of 3x3\n",
    "#   - relu (rectified linear unit) activation\n",
    "#   - input shape (from the data)\n",
    "#   - see for more options: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1), name=\"layer1\"))\n",
    "# then comes max pooling2\n",
    "#   - argument describes how much to downsample the data (by a factor of 2 in both dimensions)\n",
    "#   - see for more options: https://keras.io/layers/pooling/\n",
    "model.add(layers.MaxPooling2D((2, 2), name=\"layer2\"))\n",
    "# then convolution again (same kernel size)\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', name=\"layer3\"))\n",
    "# then max pooling again\n",
    "model.add(layers.MaxPooling2D((2, 2), name=\"layer4\"))\n",
    "# then another convolution layer\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu', name=\"layer5\"))\n",
    "\n",
    "# flatten\n",
    "model.add(layers.Flatten())\n",
    "# dense\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# the final number of outputs need to match the number of classes (one for each class)\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# compile the model\n",
    "# using:\n",
    "#   - the adam optimizer (see for more info: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "#   - categorical cross entropy (also know as: softmax!)\n",
    "#   - accuracy as the metric (FIXME)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "# how many epochs (passes through the data)\n",
    "num_epochs = 10\n",
    "\n",
    "# this will hold the performance\n",
    "perf_time = np.zeros((num_epochs, 3))\n",
    "\n",
    "# set up figure\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# training the network for num_epoch epochs\n",
    "for epoch in np.arange(0,num_epochs):\n",
    "    # train an epoch at a time, visualize as we go!\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=2, validation_data=(x_val, y_val))\n",
    "    \n",
    "    # check the performance on train/test/val\n",
    "    # the model.evaluate function returns the loss (position 0) and the performance (position 1)\n",
    "    new = [model.evaluate(x_train, y_train)[1], model.evaluate(x_val, y_val)[1], model.evaluate(x_test, y_test)[1]]\n",
    "    \n",
    "    # add to performance\n",
    "    perf_time[epoch,:]=new\n",
    "    \n",
    "    # visualize\n",
    "    plt.plot(np.arange(0,epoch+1),perf_time[0:epoch+1,0],'b', label='train')\n",
    "    plt.plot(np.arange(0,epoch+1),perf_time[0:epoch+1,1],'r', label='validation')\n",
    "    plt.plot(np.arange(0,epoch+1),perf_time[0:epoch+1,2],'g', label='test')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
