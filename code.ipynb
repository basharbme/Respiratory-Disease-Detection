{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL PATH VARIABLE FOR AUDIO / TXT FILES:\n",
    "path = 'respiratory-sound-database/audio_and_txt_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files():\n",
    "    folder = os.listdir(path)\n",
    "\n",
    "    wav_files, txt_files = [], []\n",
    "    for file in folder:\n",
    "        if file.endswith('_16.wav'):\n",
    "            wav_files.append(file)\n",
    "        elif file.endswith('.txt'):\n",
    "            txt_files.append(file)\n",
    "\n",
    "    return wav_files, txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(filename):\n",
    "    splits = filename.split('_')\n",
    "    print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# separate files by audio and txt\n",
    "wav_files, txt_files = get_audio_files()\n",
    "wav_files = sorted(wav_files)\n",
    "txt_files = sorted(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information from the wav files' filename\n",
    "# 0:[patient #], 1:[recording index], 2:[chest location], 3:[acquisition mode], 4:[recording equipment]\n",
    "stripped_file_info = [re.sub('_16\\.wav$', '', file) for file in wav_files]\n",
    "file_info = [file.split('_') for file in stripped_file_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the extracted data into a dataframe\n",
    "demog_data = pd.read_csv('demographic-info.csv')\n",
    "diag_data = pd.read_csv('respiratory-sound-database/patient_diagnosis.csv', names=['Patient Number', 'Diagnosis'])\n",
    "data = pd.DataFrame(data=file_info, columns=['Patient Number', 'Recording Index', 'Chest Location', 'Acquisition Mode', 'Recording Equipment'])\n",
    "data['Patient Number'] = data['Patient Number'].astype(int)\n",
    "data['txt_file'] = txt_files\n",
    "data['audio_file'] = wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put info from demog_data into data\n",
    "age, sex, a_BMI, c_weight, c_height, diagnosis = [], [], [], [], [], []\n",
    "demog_size = demog_data['Age'].size\n",
    "size = data['Patient Number'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make this more efficient\n",
    "for j in range(0, size):\n",
    "    for i in range(0, demog_size):\n",
    "        if data['Patient Number'][j] == demog_data['Patient Number'][i]:\n",
    "            age.append(demog_data['Age'][i])\n",
    "            sex.append(demog_data['Sex'][i])\n",
    "            a_BMI.append(demog_data['Adult BMI'][i])\n",
    "            c_weight.append(demog_data['Child Weight'][i])\n",
    "            c_height.append(demog_data['Child Height'][i])\n",
    "        if data['Patient Number'][j] == diag_data['Patient Number'][i]:\n",
    "            diagnosis.append(diag_data['Diagnosis'][i])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'], data['Sex'], data['Adult BMI'], data['Child Weight'], data['Child Height'], data['Diagnosis'] = age, sex, a_BMI, c_weight, c_height, diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# function to get spectrogram from a wav file\n",
    "def get_spectro(file_path):\n",
    "    sample_rate, samples = wavfile.read(path + file_path)\n",
    "    Pxx, freqs, bins, im = plt.specgram(samples[:], NFFT=1024, Fs=44100, noverlap=900)\n",
    "\n",
    "    save_path = path + 'spectrograms/' + re.sub('\\.wav$', '_spec', file_path)\n",
    "    plt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "spectrograms = [f for f in os.listdir(path + 'spectrograms/')]\n",
    "spectrograms.remove('.DS_Store')\n",
    "spectrograms.sort()\n",
    "\n",
    "data['spec_file'] = spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split\n",
    "# Notes: I'm splitting this manually so that the data is \"speaker\" independent.\n",
    "# Important: the range of patient numbers is 101 - 226.\n",
    "end = 226\n",
    "beg = 101\n",
    "# train_ind is the SPEAKER index that signifies the end of the training set. testing and val will have other speaker data in them.\n",
    "train_ind = np.floor(0.7 * (end - beg) + beg)\n",
    "test_ind = np.floor(0.5 * (end - train_ind) + train_ind)\n",
    "val_ind = 226\n",
    "\n",
    "# find row index where train_ind ends\n",
    "row = 0\n",
    "for i in range(0, len(data.index)):\n",
    "    if data['Patient Number'][i] == train_ind:\n",
    "        row = i\n",
    "\n",
    "train_data = data.loc[:row, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test split\n",
    "test_row = [i for i in range(row, len(data.index)) if data['Patient Number'][i] == test_ind]\n",
    "test_data = data.loc[row + 1:test_row[-1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_row = [i for i in range(row, len(data.index)) if data['Patient Number'][i] == val_ind]\n",
    "val_data = data.loc[test_row[-1] + 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['spec_file'], train_data['Diagnosis']\n",
    "X_test, y_test = test_data['spec_file'], test_data['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not a bitmap",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-211c8b9cf90c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'spectrograms/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobitmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# summarize some details about the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobitmap\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not a bitmap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xbm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         return b\"\".join(\n",
      "\u001b[0;31mValueError\u001b[0m: not a bitmap"
     ]
    }
   ],
   "source": [
    "image = Image.open(path + 'spectrograms/' + X_train[0])\n",
    "\n",
    "# summarize some details about the image\n",
    "# print(image.format)\n",
    "# print(image.size)\n",
    "# print(image.mode)\n",
    "# show the image\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n  175  26 166 255 247 127   0   0   0   0]\n [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n  225 172 253 242 195  64   0   0   0   0]\n [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n   93  82  82  56  39   0   0   0   0   0]\n [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n   25   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n  150  27   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n  253 187   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n  253 249  64   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n  253 207   2   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n  250 182   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n   78   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0   0   0   0   0   0   0   0]]\n"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: @Priya\n",
    "# 2. Look into training CNN on spectrograms\n",
    "# 3. Train CNN on spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}